{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Plotting MAPIE score conformal predictions with a toy dataset\n\nAn example plot of :class:`mapie.classification.MapieClassifier`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy as np\nimport matplotlib.pyplot as plt\n\nfrom sklearn.datasets import make_blobs\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\n\nfrom mapie.classification import MapieClassifier\n\n# Create training, and calibration datasets from blobs\ncenters = [(-5, -5), (5, -5), (-5, 5), (5, 5)]\nx_min, x_max, y_min, y_max, step = -15, 15, -15, 15, 0.1\nX_train_val, y_train_val = make_blobs(\n    n_samples=1000,\n    n_features=2,\n    centers=centers,\n    cluster_std=2.5,\n    random_state=59\n)\nX_train, X_val, y_train, y_val = train_test_split(\n    X_train_val, y_train_val, test_size=0.25, random_state=42\n)\n# Create test from (x, y) coordinates\nX_test = np.stack([\n    [x, y]\n    for x in np.arange(x_min, x_max, step)\n    for y in np.arange(x_min, x_max, step)\n])\n\n# Fit a Logistic Regression model on the training set\nclf = LogisticRegression(multi_class=\"multinomial\")\nclf.fit(X_train, y_train)\ny_pred = clf.predict(X_test)\ny_pred_proba = clf.predict_proba(X_test)\ny_pred_proba_max = np.max(y_pred_proba, axis=1)\n\n# Apply MapieClassifier on the calibration set to get prediction sets\nmapie = MapieClassifier(estimator=clf, cv=\"prefit\")\nmapie.fit(X_val, y_val)\ny_pred_mapie, y_pi_mapie = mapie.predict(X_test, alpha=0.01)\ny_pi_sums = y_pi_mapie.sum(axis=1)\n\n# Plot the results\ntab10 = plt.cm.get_cmap('Purples', 4)\ncolors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728']\ny_pred_col = [colors[i] for _, i in enumerate(y_pred)]\ny_train_col = [colors[i] for _, i in enumerate(y_train)]\nfig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(20, 5))\nax1.scatter(\n    X_test[:, 0],\n    X_test[:, 1],\n    color=y_pred_col,\n    marker='.',\n    s=1, alpha=0.4\n)\nax1.scatter(\n    X_train[:, 0],\n    X_train[:, 1],\n    color=y_train_col,\n    marker='o',\n    s=10,\n    edgecolor='k'\n)\nax1.set_title(\"Predicted labels\")\nmax_probs = ax2.scatter(\n    X_test[:, 0],\n    X_test[:, 1],\n    c=y_pred_proba_max,\n    marker='.',\n    s=2,\n    alpha=0.4,\n    cmap=\"Purples\"\n)\nax2.scatter(\n    X_train[:, 0],\n    X_train[:, 1],\n    marker='o',\n    color=y_train_col,\n    s=10,\n    edgecolor='k'\n)\ncbar = plt.colorbar(max_probs, ax=ax2)\nax2.set_title(\"Maximum probabilities\")\nnum_labels = ax3.scatter(\n    X_test[:, 0],\n    X_test[:, 1],\n    c=y_pi_sums,\n    marker='.',\n    s=2,\n    alpha=1,\n    cmap=tab10\n)\nax3.scatter(\n    X_train[:, 0],\n    X_train[:, 1],\n    marker='o',\n    color=y_train_col,\n    s=10,\n    edgecolor='k'\n)\ncbar = plt.colorbar(num_labels, ax=ax3)\nax3.set_title(\"Number of labels in prediction sets\")\nplt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}