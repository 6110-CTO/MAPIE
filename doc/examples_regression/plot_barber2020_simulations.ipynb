{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Reproducing the simulations from Foygel-Barber et al. (2020)\n\n:class:`mapie.regression.MapieRegressor` is used to investigate\nthe coverage level and the prediction interval width as a function\nof the dimension using simulated data points as introduced in\nFoygel-Barber et al. (2021) [1].\n\nThis simulation generates several times linear data with random noise\nwhose signal-to-noise is equal to 10 and for several given dimensions.\n\nHere we use MAPIE, with a LinearRegression base model, to estimate the width\nmeans and the coverage levels of the prediction intervals estimated by all the\navailable strategies as function of the dataset dimension.\n\nWe then show the prediction interval coverages and widths as a function of the\ndimension values for selected strategies with standard error given by\nthe different trials.\n\nThis simulation is carried out to emphasize the instability of the prediction\nintervals estimated by the jackknife strategy when the dataset dimension is\nequal to the number of training samples (here 100).\n\n[1]\u00a0Rina Foygel Barber, Emmanuel J. Cand\u00e8s,\nAaditya Ramdas, and Ryan J. Tibshirani.\n\"Predictive inference with the jackknife+.\"\nAnn. Statist., 49(1):486\u2013507, February 2021.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from typing import List, Dict, Any\n\nimport numpy as np\nfrom sklearn.linear_model import LinearRegression\nfrom matplotlib import pyplot as plt\n\nfrom mapie.regression import MapieRegressor\nfrom mapie.metrics import regression_coverage_score\n\n\ndef PIs_vs_dimensions(\n    strategies: Dict[str, Any],\n    alpha: float,\n    n_trial: int,\n    dimensions: List[int]\n) -> Dict[str, Dict[int, Dict[str, np.ndarray]]]:\n    \"\"\"\n    Compute the prediction intervals for a linear regression problem.\n    Function adapted from Foygel-Barber et al. (2020).\n\n    It generates several times linear data with random noise whose\n    signal-to-noise     is equal to 10 and for several given dimensions,\n    given by the dimensions list.\n\n    Here we use MAPIE, with a LinearRegression base model, to estimate\n    the width means and the coverage levels of the prediction intervals\n    estimated by all the available strategies as a function of\n    the dataset dimension.\n\n    This simulation is carried out to emphasize the instability\n    of the prediction intervals estimated by the Jackknife strategy\n    when the dataset dimension is equal to the number\n    of training samples (here 100).\n\n    Parameters\n    ----------\n    strategies : Dict[str, Dict[str, Any]]\n        List of strategies for estimating prediction intervals,\n        with corresponding parameters.\n    alpha : float\n        1 - (target coverage level).\n    n_trial : int\n        Number of trials for each dimension for estimating\n        prediction intervals.\n        For each trial, a new random noise is generated.\n    dimensions : List[int]\n        List of dimension values of input data.\n\n    Returns\n    -------\n    Dict[str, Dict[int, Dict[str, np.ndarray]]]\n        Prediction interval widths and coverages for each strategy, trial,\n        and dimension value.\n    \"\"\"\n    n_train = 100\n    n_test = 100\n    SNR = 10\n    results: Dict[str, Dict[int, Dict[str, np.ndarray]]] = {\n        strategy: {\n            dimension: {\n                \"coverage\": np.empty(n_trial),\n                \"width_mean\": np.empty(n_trial)\n            } for dimension in dimensions\n        } for strategy in strategies\n    }\n    for dimension in dimensions:\n        for trial in range(n_trial):\n            beta = np.random.normal(size=dimension)\n            beta_norm = np.sqrt((beta**2).sum())\n            beta = beta/beta_norm*np.sqrt(SNR)\n            X_train = np.random.normal(size=(n_train, dimension))\n            noise_train = np.random.normal(size=n_train)\n            noise_test = np.random.normal(size=n_test)\n            y_train = X_train.dot(beta) + noise_train\n            X_test = np.random.normal(size=(n_test, dimension))\n            y_test = X_test.dot(beta) + noise_test\n\n            for strategy, params in strategies.items():\n                mapie = MapieRegressor(\n                    LinearRegression(),\n                    ensemble=True,\n                    n_jobs=-1,\n                    **params\n                )\n                mapie.fit(X_train, y_train)\n                y_pred, y_pis = mapie.predict(X_test, alpha=alpha)\n                results[strategy][dimension][\"coverage\"][trial] = (\n                    regression_coverage_score(y_test, y_pis[:, 0, 0], y_pis[:, 1, 0])\n                )\n                results[strategy][dimension][\"width_mean\"][trial] = (\n                    y_pis[:, 1, 0] - y_pis[:, 0, 0]\n                ).mean()\n    return results\n\n\ndef plot_simulation_results(\n    results: Dict[str, Dict[int, Dict[str, np.ndarray]]],\n    title: str\n) -> None:\n    \"\"\"\n    Show the prediction interval coverages and widths as a function\n    of dimension values for selected strategies with standard error\n    given by different trials.\n\n    Parameters\n    ----------\n    results : Dict[str, Dict[int, Dict[str, np.ndarray]]]\n        Prediction interval widths and coverages for each strategy, trial,\n        and dimension value.\n    title : str\n        Title of the plot.\n    \"\"\"\n    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n    plt.rcParams.update({\"font.size\": 14})\n    plt.suptitle(title)\n    for strategy in results:\n        dimensions = list(results[strategy].keys())\n        n_dim = len(dimensions)\n        coverage_mean, coverage_SE, width_mean, width_SE = (\n            np.zeros(n_dim), np.zeros(n_dim), np.zeros(n_dim), np.zeros(n_dim)\n        )\n        for idim, dim in enumerate(dimensions):\n            coverage_mean[idim] = (\n                results[strategy][dim][\"coverage\"].mean()\n            )\n            coverage_SE[idim] = (\n                results[strategy][dim][\"coverage\"].std()/np.sqrt(ntrial)\n            )\n            width_mean[idim] = (\n                results[strategy][dim][\"width_mean\"].mean()\n            )\n            width_SE[idim] = (\n                results[strategy][dim][\"width_mean\"].std()/np.sqrt(ntrial)\n            )\n        ax1.plot(dimensions, coverage_mean, label=strategy)\n        ax1.fill_between(\n            dimensions,\n            coverage_mean - coverage_SE,\n            coverage_mean + coverage_SE,\n            alpha=0.25\n        )\n        ax2.plot(dimensions, width_mean, label=strategy)\n        ax2.fill_between(\n            dimensions,\n            width_mean - width_SE,\n            width_mean + width_SE,\n            alpha=0.25\n        )\n    ax1.axhline(1 - alpha, linestyle=\"dashed\", c=\"k\")\n    ax1.set_ylim(0.0, 1.0)\n    ax1.set_xlabel(\"Dimension d\")\n    ax1.set_ylabel(\"Coverage\")\n    ax1.legend()\n    ax2.set_ylim(0, 20)\n    ax2.set_xlabel(\"Dimension d\")\n    ax2.set_ylabel(\"Interval width\")\n    ax2.legend()\n\n\nSTRATEGIES = {\n    \"naive\": dict(method=\"naive\"),\n    \"cv\": dict(method=\"base\", cv=5),\n    \"cv_plus\": dict(method=\"plus\", cv=5)\n}\nalpha = 0.1\nntrial = 3\ndimensions = np.arange(10, 150, 10)\nresults = PIs_vs_dimensions(STRATEGIES, alpha, ntrial, dimensions)\nplot_simulation_results(results, title=\"Coverages and interval widths\")\nplt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}