{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Estimating prediction intervals of time series forecast\nThis example uses :class:`mapie.regression.MapieRegressor` to estimate\nprediction intervals associated with time series forecast. We use the\nstandard cross-validation approach to estimate residuals and associated\nprediction intervals.\n\nWe use here the Victoria electricity demand dataset used in the book\n\"Forecasting: Principles and Practice\" by R. J. Hyndman and G. Athanasopoulos.\nThe electricity demand features daily and weekly seasonalities and is impacted\nby the temperature, considered here as a exogeneous variable.\n\nThe data is modelled by a Random Forest model with a\n:class:`sklearn.model_selection.RandomizedSearchCV` using a sequential\n:class:`sklearn.model_selection.TimeSeriesSplit` cross validation, in which the\ntraining set is prior to the validation set.\nThe best model is then feeded into :class:`mapie.regression.MapieRegressor`\nto estimate the associated prediction intervals.\nWe consider the standard CV+ resampling method.\n\nWe wish to emphasize one main limitation with this example.\nWe use a standard cross-validation in Mapie to estimate the prediction\nintervals, through the `sklearn.model_selection.KFold()` object.\nResiduals are therefore estimated using models trained on data with higher\nindices than the validation data, which is inappropriate for time-series data.\nHowerver, using a `sklearn.model_selection.TimeSeriesSplit` cross validation\nobject for estimating the residuals breaks the theoretical guarantees of the\nJackknife+ and CV+ methods.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import pandas as pd\nfrom scipy.stats import randint\nfrom matplotlib import pylab as plt\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.model_selection import RandomizedSearchCV, TimeSeriesSplit\nfrom mapie.regression import MapieRegressor\nfrom mapie.metrics import regression_coverage_score\n\n# Load input data and feature engineering\ndemand_df = pd.read_csv(\n    \"../data/demand_temperature.csv\",\n    parse_dates=True,\n    index_col=0\n)\ndemand_df[\"Date\"] = pd.to_datetime(demand_df.index)\ndemand_df[\"Weekofyear\"] = demand_df.Date.dt.isocalendar().week.astype('int64')\ndemand_df[\"Weekday\"] = demand_df.Date.dt.isocalendar().day.astype('int64')\ndemand_df[\"Hour\"] = demand_df.index.hour\n\n# Train/validation/test split\nnum_test_steps = 24*7*2\ndemand_train = demand_df.iloc[:-num_test_steps, :].copy()\ndemand_test = demand_df.iloc[-num_test_steps:, :].copy()\nX_train = demand_train.loc[:, [\"Weekofyear\", \"Weekday\", \"Hour\", \"Temperature\"]]\ny_train = demand_train[\"Demand\"]\nX_test = demand_test.loc[:, [\"Weekofyear\", \"Weekday\", \"Hour\", \"Temperature\"]]\ny_test = demand_test[\"Demand\"]\n\n# CV parameter search\nn_iter = 10\nn_splits = 5\ntscv = TimeSeriesSplit(n_splits=n_splits)\nrandom_state = 59\nrf_model = RandomForestRegressor(random_state=random_state)\nrf_params = {\n    \"max_depth\": randint(2, 30),\n    \"n_estimators\": randint(10, 1e3)\n}\ncv_obj = RandomizedSearchCV(\n    rf_model,\n    param_distributions=rf_params,\n    n_iter=n_iter,\n    cv=tscv,\n    scoring=\"neg_root_mean_squared_error\",\n    random_state=random_state,\n    verbose=0,\n    n_jobs=-1,\n)\ncv_obj.fit(X_train, y_train)\nbest_est = cv_obj.best_estimator_\n\n# Estimate prediction intervals on test set with best estimator\n# Here, a non-nested CV approach is used for the sake of computational\n# time, but a nested CV approach is preferred.\n# See the dedicated example in the gallery for more information.\nalpha = 0.1\nmapie = MapieRegressor(\n    best_est,\n    method=\"plus\",\n    cv=n_splits,\n    ensemble=True,\n    n_jobs=-1\n)\nmapie.fit(X_train, y_train)\ny_pred, y_pis = mapie.predict(X_test, alpha=alpha)\ncoverage = regression_coverage_score(\n    y_test, y_pis[:, 0, 0], y_pis[:, 1, 0]\n)\nwidth = (y_pis[:, 1, 0] - y_pis[:, 0, 0]).mean()\n\n# Print results\nprint(\n    \"Coverage and prediction interval width mean for CV+: \"\n    f\"{coverage:.3f}, {width:.3f}\"\n)\n\n# Plot estimated prediction intervals on test set\nfig = plt.figure(figsize=(15, 5))\nax = fig.add_subplot(1, 1, 1)\nax.set_ylabel(\"Hourly demand (GW)\")\nax.plot(demand_test.Demand, lw=2, label=\"Test data\", c=\"C1\")\nax.plot(\n    demand_test.index,\n    y_pred,\n    lw=2,\n    c=\"C2\",\n    label=\"Predictions\"\n)\nax.fill_between(\n    demand_test.index,\n    y_pis[:, 0, 0],\n    y_pis[:, 1, 0],\n    color=\"C2\",\n    alpha=0.2,\n    label=\"CV+ PIs\"\n)\nax.legend()\nplt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}